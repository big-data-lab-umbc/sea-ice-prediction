{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d41b2a3-c140-4745-a003-cf3018ac675b",
   "metadata": {},
   "source": [
    "# **Spatiotemporal models**\n",
    "\n",
    "**Contains:** Spatiotemporal architecture\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96face63-6386-42ab-89ca-1cf39184cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "# STUDY\n",
    "# Utilities\n",
    "import sys\n",
    "sys.path.append(\"../transformers/\")\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import os, cv2\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Model\n",
    "from fftstack import FFTTransformer\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7493687c-7c1b-4bf1-9680-e4d4fdaab1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convenience functions\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "def nrmse(true, pred):\n",
    "    return mean_squared_error(true, pred, squared=False)/float(true.mean())\n",
    "\n",
    "def yearly_linreg_p(true, pred):\n",
    "    df = pd.concat((true, pred), axis=1).groupby(true.index.year)\n",
    "    rmse_ = []\n",
    "    for row in df:\n",
    "        rmse_.append(rmse(row[1].iloc[:, 0], row[1].iloc[:, 1]))\n",
    "    yearly_true_rmse = pd.Series(rmse_, index=list(true.index.year.drop_duplicates()))\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(yearly_true_rmse.values, yearly_true_rmse.index)\n",
    "    return p_value\n",
    "\n",
    "def in_range(start, end, step=1):\n",
    "    return list(range(start, end+step, step))\n",
    "\n",
    "def make_dir(root, name):\n",
    "    return root+name\n",
    "\n",
    "def build_directory(directory):\n",
    "    directory_array = list(filter(None, (f\"/{directory}\").split(\"/\")[1:]))\n",
    "    for i in range(1, len(directory_array) + 1):\n",
    "        try:\n",
    "            os.mkdir(\"/\".join(directory_array[0:i]))\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "def make_video(img_dir, save_dir):\n",
    "    video_name = save_dir + '.mp4'\n",
    "    images = [img for img in os.listdir(img_dir) if img.endswith(\".png\")]\n",
    "    frame = cv2.imread(os.path.join(img_dir, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "    video = cv2.VideoWriter(video_name, 0, 5, (width,height), 0)\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(img_dir, image)))\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9c382",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c43af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  408 ent_v3.0\n",
      "test:  104\n"
     ]
    }
   ],
   "source": [
    "fetch_folder_dir = \"data/sie-csv/\"\n",
    "\n",
    "pixelwise_data = []\n",
    "for file in os.listdir(fetch_folder_dir):\n",
    "    year, month = file[2:6], file[6:8]\n",
    "    cur_img = list(np.loadtxt(fetch_folder_dir + file, delimiter=\",\", dtype=int).reshape(1,136192)[0])\n",
    "    pixelwise_data.append([f\"{year}-{month}\"] + cur_img)\n",
    "    print(file[0:len(file)-4], end=\"\\r\")\n",
    "    \n",
    "pixelwise_data = pd.DataFrame(pixelwise_data, columns=[\"date\"]+list(range(136192))).set_index(\"date\", drop=True)\n",
    "pixelwise_data.index = pd.to_datetime(pixelwise_data.index, infer_datetime_format=True)\n",
    "pixelwise_data = pixelwise_data.asfreq(\"MS\").fillna(0)\n",
    "\n",
    "col_names = pixelwise_data.columns\n",
    "train, test = pixelwise_data.iloc[:408,], pixelwise_data.iloc[408:512,]\n",
    "\n",
    "print(\n",
    "    \"\\ntrain: \", len(train),\n",
    "    \"\\ntest: \", len(test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d58a9",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b70303d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT pipeline\n",
    "fft_pipe = FFTTransformer(train_size=0.8,\n",
    "                          iter_grid=np.arange(1,3),\n",
    "                          threshold_grid=np.arange(0.1, 1.01, 0.2),\n",
    "                          method=\"normalize\",\n",
    "                          performance_threshold=0.1,\n",
    "                          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fb9b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning search space...\n",
      "Training best models...\n",
      "136191\r"
     ]
    }
   ],
   "source": [
    "fft_train = fft_pipe.fit_transform(train)\n",
    "fft_test = fft_pipe.transform(test)\n",
    "\n",
    "build_directory(\"results/de-cycled/\")\n",
    "fft_train.to_csv(\"results/de-cycled/fft_train.csv\")\n",
    "fft_test.to_csv(\"results/de-cycled/fft_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26479353",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b689189f-2ea8-4d84-b34f-3ff41f074a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inversed_train = fft_pipe.inverse_transform(fft_train).round()\n",
    "inversed_test = fft_pipe.inverse_transform(fft_test).round()\n",
    "\n",
    "build_directory(\"results/final-predictions/\")\n",
    "inversed_train.to_csv(\"results/final-predictions/fft-train.csv\")\n",
    "inversed_test.to_csv(\"results/final-predictions/fft-test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ebbd5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69927a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationTable:\n",
    "    def __init__(self, metrics, index_col=\"model\"):\n",
    "        self.metric_names = metrics.keys()\n",
    "        self.metric_funcs = metrics.values()\n",
    "        self.table = pd.DataFrame(columns=self.metric_names)\n",
    "\n",
    "    def addEvaluation(self, name, true, pred):\n",
    "        metric_results = []\n",
    "        for metric in self.metric_funcs:\n",
    "            metric_results.append(metric(true, pred))\n",
    "        self.table.loc[name] = metric_results\n",
    "\n",
    "    def loadTable(self):\n",
    "        return self.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55768b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_train = pd.read_csv(\"results/de-cycled/fft-train.csv\").set_index(\"date\", drop=True)\n",
    "fft_test = pd.read_csv(\"results/de-cycled/fft-test.csv\").set_index(\"date\", drop=True)\n",
    "fft_train.index = pd.to_datetime(fft_train.index, infer_datetime_format=True)\n",
    "fft_train.columns = list(range(136192))\n",
    "fft_test.index = pd.to_datetime(fft_test.index, infer_datetime_format=True)\n",
    "fft_test.columns = list(range(136192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8403aab4-7fb8-4cbc-8442-759a47e36621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ice_extent(array, areas):\n",
    "    array = array / 100.00\n",
    "    tot_ice_extent = np.sum(np.multiply(array, areas), axis=(1,2))\n",
    "    return tot_ice_extent\n",
    "\n",
    "area_size = np.fromfile(\"data/psn25area_v3.dat\", dtype=np.dtype('<i')).reshape(448,304)/1000.0\n",
    "\n",
    "fft_train_SIE = calc_ice_extent(np.array(fft_train, dtype=np.uint8).reshape(408, 448, 304), area_size)\n",
    "fft_test_SIE = calc_ice_extent(np.array(fft_test, dtype=np.uint8).reshape(104, 448, 304), area_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "957dc979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>yearly_linreg_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fft-train-rmse</th>\n",
       "      <td>350914.449859</td>\n",
       "      <td>0.414254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fft-test-rmse</th>\n",
       "      <td>359658.591198</td>\n",
       "      <td>0.098330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rmse  yearly_linreg_p\n",
       "fft-train-rmse  350914.449859         0.414254\n",
       "fft-test-rmse   359658.591198         0.098330"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\"rmse\": rmse,\n",
    "           \"yearly_linreg_p\": yearly_linreg_p}\n",
    "\n",
    "fft_stack_eval = EvaluationTable(metrics)\n",
    "\n",
    "fft_stack_eval.addEvaluation(\"fft-train-rmse\", pd.Series(np.zeros(408), index=train.index), pd.Series(fft_train_SIE, index=train.index))\n",
    "fft_stack_eval.addEvaluation(\"fft-test-rmse\", pd.Series(np.zeros(104), index=test.index), pd.Series(fft_test_SIE, index=test.index))\n",
    "\n",
    "results_table = fft_stack_eval.loadTable()\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04c70d",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18be3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_directory(\"results/final-predictions/decycled-train-img/\")\n",
    "for num, row in enumerate(fft_train.index.date):\n",
    "    post_img = (np.array(fft_train.iloc[num], dtype=np.uint8)*255).reshape(448, 304)\n",
    "    Image.fromarray(post_img, mode=\"L\").save(f\"results/final-predictions/decycled-train-img/{str(row)}.png\")\n",
    "\n",
    "build_directory(\"results/final-predictions/decycled-test-img/\")\n",
    "for num, row in enumerate(fft_test.index.date):\n",
    "    post_img = (np.array(fft_test.iloc[num], dtype=np.uint8)*255).reshape(448, 304)\n",
    "    Image.fromarray(post_img, mode=\"L\").save(f\"results/final-predictions/decycled-test-img/{str(row)}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b17b0ec-b56c-41a6-969e-8383733e8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_directory(\"results/final-predictions/final-train-img/\")\n",
    "for num, row in enumerate(inversed_train.index.date):\n",
    "    post_img = (np.array(inversed_train.iloc[num], dtype=np.uint8)*255).reshape(448, 304)\n",
    "    Image.fromarray(post_img, mode=\"L\").save(f\"results/final-predictions/final-train-img/{str(row)}.png\")\n",
    "\n",
    "build_directory(\"results/final-predictions/final-test-img/\")\n",
    "for num, row in enumerate(inversed_test.index.date):\n",
    "    post_img = (np.array(inversed_test.iloc[num], dtype=np.uint8)*255).reshape(448, 304)\n",
    "    Image.fromarray(post_img, mode=\"L\").save(f\"results/final-predictions/final-test-img/{str(row)}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2515375-b194-41da-a6aa-4741d88f4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_video(\"results/final-predictions/decycled-train-img/\", \"results/final-predictions/decycled-train-vid\")\n",
    "make_video(\"results/final-predictions/decycled-test-img/\", \"results/final-predictions/decycled-test-vid\")\n",
    "make_video(\"results/final-predictions/final-train-img/\", \"results/final-predictions/final-train-vid\")\n",
    "make_video(\"results/final-predictions/final-test-img/\", \"results/final-predictions/final-test-vid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
